1
00:00:01,979 --> 00:00:08,570
Now let us look at how to configure Hadoop.
Hadoop is configured using a number of XML

2
00:00:08,570 --> 00:00:15,570
files. And each file controls a number of
parameters. There are three main configuration

3
00:00:16,750 --> 00:00:21,640
files with which you will work. core-site.xml
is

4
00:00:21,640 --> 00:00:28,640
used to configure the parameters that are
common to both HDFS and MapReduce. hdfs-site.xml

5
00:00:34,140 --> 00:00:41,140
contains parameters that are for the HDFS
daemons, like the NameNode and DataNodes.

6
00:00:43,469 --> 00:00:50,469
mapred-site.xml controls the settings for
MapReduce daemons, JobTracker and TaskTrackers.

7
00:00:54,870 --> 00:01:00,410
We are not going to spend the time covering
all of the configuration files. That would

8
00:01:00,410 --> 00:01:07,410
just take
too much time. However, you do have the option

9
00:01:07,510 --> 00:01:10,180
of pausing this video if you would like to
read

10
00:01:10,180 --> 00:01:17,180
the descriptions of the other configuration
files.

11
00:01:18,660 --> 00:01:25,660
The hadoop-env.sh is a script that sets a
number of environment variables. Normally,

12
00:01:26,320 --> 00:01:29,720
with
Hadoop, these variables are not set but with

13
00:01:29,720 --> 00:01:34,640
BigInsights, they are. There is one that must
always

14
00:01:34,640 --> 00:01:41,640
be set and that is the JAVA_HOME environment
variable.

15
00:01:41,990 --> 00:01:48,990
Here are some of the settings found in core-site.xml.
We are not going to spend time on these

16
00:01:49,350 --> 00:01:55,780
nor those on this page as well. If you want
to pause the video to read their description,

17
00:01:55,780 --> 00:01:59,310
feel free
to do so.

18
00:01:59,310 --> 00:02:06,310
Next we have some setting in hdfs-site.xml.
If you want to set a different value for the

19
00:02:07,850 --> 00:02:13,879
default
block size, then you would modify dfs.block.size.

20
00:02:13,879 --> 00:02:20,879
Likcwise, if you want to change the default
replication factor, then you would modify

21
00:02:21,319 --> 00:02:28,319
dfs.replication. Once again, I am not going
to cover all

22
00:02:31,349 --> 00:02:38,349
the parameters.
To change MapReduce settings, you modify mapred-site.xml.

23
00:02:38,489 --> 00:02:45,489
You can control which nodes can
connect to the JobTracker. mapred.reduce.tasks

24
00:02:46,760 --> 00:02:53,760
lets you set the number of reduce tasks per
job.

25
00:02:53,969 --> 00:03:00,969
mapred.map.tasks.speculative. execution allows
the JobTracker, when having determined that

26
00:03:02,749 --> 00:03:09,749
there might be a problem with one map task,
to start another map task running in parallel.

27
00:03:10,340 --> 00:03:13,569
Both
map tasks process the same data and, upon

28
00:03:13,569 --> 00:03:17,230
successful completion of one of the tasks,
the other is

29
00:03:17,230 --> 00:03:24,230
terminated. mapred.tasktracker.map.tasks.maximum
and

30
00:03:27,450 --> 00:03:34,450
mapred.tasktracker.reduce.tasks.maximum lets
you define the number of slots on a TaskTracker

31
00:03:38,859 --> 00:03:45,859
that can run map and reduce task. mapred.jobtracker.taskScheduler
points to the scheduler that is

32
00:03:49,829 --> 00:03:56,829
to be used for MapReduce jobs.
So how do you set these parameters? First

33
00:03:57,950 --> 00:04:00,909
of all, you must stop the appropriate service
or

34
00:04:00,909 --> 00:04:07,909
services before making the change. You are
making changes to value element for the appropriate

35
00:04:08,700 --> 00:04:15,700
property element. The configuration files
are in the hadoop-conf directory. The changes

36
00:04:18,180 --> 00:04:22,390
must be
made to the configuration files on all nodes

37
00:04:22,390 --> 00:04:29,390
in the cluster.
Let me spend a few minutes and focus on BigInsights.

38
00:04:30,690 --> 00:04:37,690
With BigInsights the hadoop-conf
directory is under $BIGINSIGHTS_HOME. But,

39
00:04:40,410 --> 00:04:47,410
and this is very important, you do not make
changes to the configuration files in that

40
00:04:48,570 --> 00:04:53,570
directory. BigInsights has a staging directory
which is

41
00:04:53,570 --> 00:05:00,570
$BIGINSIGHTS_HOME/hdm/hadoop-conf-staging
that has copies of the configuration files.

42
00:05:12,410 --> 00:05:19,410
You make changes to the files in this staging
directory and then execute a script that distributes

43
00:05:19,590 --> 00:05:26,590
the changes to all nodes in the cluster.
Finally, let us talk about setting up rack

44
00:05:28,880 --> 00:05:34,250
topology.
To make Hadoop aware of the cluster’s topology,

45
00:05:34,250 --> 00:05:41,250
you code a script that receives as arguments,
one or more ip addresses of nodes in the cluster.

46
00:05:42,700 --> 00:05:49,700
The script returns on stdout, a list of rack
names, one for each input value. Then you

47
00:05:53,880 --> 00:06:00,880
update core-site.xml and modify the
topology.script.file.name property to point

48
00:06:02,830 --> 00:06:06,500
to your script. The good news is that there
are

49
00:06:06,500 --> 00:06:13,500
examples available for you to review.
This ends this unit. Thank you for attending.

50
00:06:15,400 --> 00:06:19,010
And here are some trademarks that may have
been referenced in this presentation.

